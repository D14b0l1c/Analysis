#!/usr/bin/env python3
"""
NVD Updater for Vulnerability Assessment Pipeline
Downloads latest CVE data from NVD API and processes it for vulnerability matching.
"""

import os
import json
import requests
import pandas as pd
from datetime import datetime, timedelta
import time
import sys


class NVDUpdater:
    def __init__(self):
        self.base_url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
        self.nvd_dir = os.path.join("exploit_db", "nvd")
        self.results_per_page = 2000
        
    def download_recent_cves(self, days_back=30):
        """Download CVEs from the last N days"""
        
        # Calculate date range
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)
        
        start_str = start_date.strftime("%Y-%m-%dT%H:%M:%S.000")
        end_str = end_date.strftime("%Y-%m-%dT%H:%M:%S.000")
        
        print(f"[*] Downloading CVEs from {start_str} to {end_str}")
        
        # API parameters
        params = {
            'startIndex': 0,
            'resultsPerPage': self.results_per_page,
            'lastModStartDate': start_str,
            'lastModEndDate': end_str
        }
        
        all_cves = []
        start_index = 0
        
        while True:
            params['startIndex'] = start_index
            
            try:
                print(f"[*] Fetching CVEs starting at index {start_index}...")
                response = requests.get(self.base_url, params=params, timeout=30)
                response.raise_for_status()
                
                data = response.json()
                
                if 'vulnerabilities' not in data:
                    print(f"[!] No vulnerabilities field in response")
                    break
                    
                vulnerabilities = data['vulnerabilities']
                
                if not vulnerabilities:
                    print(f"[*] No more CVEs to fetch")
                    break
                    
                all_cves.extend(vulnerabilities)
                print(f"[*] Retrieved {len(vulnerabilities)} CVEs")
                
                # Check if we got all results
                if len(vulnerabilities) < self.results_per_page:
                    break
                    
                start_index += self.results_per_page
                
                # Rate limiting - NVD recommends 6 requests per minute
                time.sleep(10)
                
            except requests.exceptions.RequestException as e:
                print(f"[!] Error fetching CVEs: {e}")
                break
                
        print(f"[✓] Total CVEs downloaded: {len(all_cves)}")
        return all_cves
        
    def download_2025_cves(self):
        """Download all 2025 CVEs"""
        
        print(f"[*] Downloading all 2025 CVEs...")
        
        params = {
            'startIndex': 0,
            'resultsPerPage': self.results_per_page,
            'pubStartDate': '2025-01-01T00:00:00.000',
            'pubEndDate': '2025-12-31T23:59:59.999'
        }
        
        all_cves = []
        start_index = 0
        
        while True:
            params['startIndex'] = start_index
            
            try:
                print(f"[*] Fetching 2025 CVEs starting at index {start_index}...")
                response = requests.get(self.base_url, params=params, timeout=30)
                response.raise_for_status()
                
                data = response.json()
                
                if 'vulnerabilities' not in data:
                    print(f"[!] No vulnerabilities field in response")
                    break
                    
                vulnerabilities = data['vulnerabilities']
                
                if not vulnerabilities:
                    print(f"[*] No more 2025 CVEs to fetch")
                    break
                    
                all_cves.extend(vulnerabilities)
                print(f"[*] Retrieved {len(vulnerabilities)} 2025 CVEs")
                
                if len(vulnerabilities) < self.results_per_page:
                    break
                    
                start_index += self.results_per_page
                time.sleep(10)  # Rate limiting
                
            except requests.exceptions.RequestException as e:
                print(f"[!] Error fetching 2025 CVEs: {e}")
                break
                
        print(f"[✓] Total 2025 CVEs downloaded: {len(all_cves)}")
        return all_cves
    
    def process_cves(self, cves_data):
        """Process CVE data into structured format"""
        
        processed_cves = []
        
        for item in cves_data:
            try:
                cve_data = item.get('cve', {})
                
                # Extract basic info
                cve_id = cve_data.get('id', '')
                published = cve_data.get('published', '')
                modified = cve_data.get('lastModified', '')
                
                # Extract description
                descriptions = cve_data.get('descriptions', [])
                description = ""
                for desc in descriptions:
                    if desc.get('lang') == 'en':
                        description = desc.get('value', '')
                        break
                
                # Extract CVSS scores
                metrics = cve_data.get('metrics', {})
                cvss_v3_score = ""
                cvss_v3_vector = ""
                cvss_v3_severity = ""
                
                # Try CVSS v3.1 first, then v3.0
                for version in ['cvssMetricV31', 'cvssMetricV30']:
                    if version in metrics:
                        cvss_metrics = metrics[version]
                        if cvss_metrics:
                            cvss_data = cvss_metrics[0].get('cvssData', {})
                            cvss_v3_score = cvss_data.get('baseScore', '')
                            cvss_v3_vector = cvss_data.get('vectorString', '')
                            cvss_v3_severity = cvss_data.get('baseSeverity', '')
                            break
                
                # Extract affected vendors/products
                configurations = cve_data.get('configurations', [])
                vendors = set()
                products = set()
                
                for config in configurations:
                    nodes = config.get('nodes', [])
                    for node in nodes:
                        cpe_matches = node.get('cpeMatch', [])
                        for cpe_match in cpe_matches:
                            criteria = cpe_match.get('criteria', '')
                            if criteria.startswith('cpe:2.3:'):
                                parts = criteria.split(':')
                                if len(parts) >= 5:
                                    vendors.add(parts[3])
                                    products.add(parts[4])
                
                # Extract CWE information
                weaknesses = cve_data.get('weaknesses', [])
                cwe_ids = []
                for weakness in weaknesses:
                    descriptions = weakness.get('description', [])
                    for desc in descriptions:
                        value = desc.get('value', '')
                        if value.startswith('CWE-'):
                            cwe_ids.append(value)
                
                # Extract references
                references = cve_data.get('references', [])
                reference_urls = [ref.get('url', '') for ref in references]
                
                processed_cve = {
                    'cve_id': cve_id,
                    'published': published,
                    'modified': modified,
                    'description': description,
                    'cvss_v3_score': cvss_v3_score,
                    'cvss_v3_vector': cvss_v3_vector,
                    'cvss_v3_severity': cvss_v3_severity,
                    'vendors': ';'.join(sorted(vendors)) if vendors else '',
                    'products': ';'.join(sorted(products)) if products else '',
                    'cwe_ids': ';'.join(cwe_ids) if cwe_ids else '',
                    'reference_count': len(reference_urls),
                    'references': ';'.join(reference_urls[:5]) if reference_urls else ''  # Limit to first 5
                }
                
                processed_cves.append(processed_cve)
                
            except Exception as e:
                print(f"[!] Error processing CVE: {e}")
                continue
        
        return processed_cves
    
    def save_data(self, cves_data, filename_prefix="nvd"):
        """Save CVE data to JSON and CSV files"""
        
        # Save raw JSON (no timestamp)
        json_file = os.path.join(self.nvd_dir, f"{filename_prefix}.json")
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump({'vulnerabilities': cves_data}, f, indent=2)
        print(f"[✓] Raw data saved to: {json_file}")
        
        # Process and save CSV
        processed_data = self.process_cves(cves_data)
        
        if processed_data:
            csv_file = os.path.join(self.nvd_dir, f"flattened_{filename_prefix}.csv")
            df = pd.DataFrame(processed_data)
            df.to_csv(csv_file, index=False)
            print(f"[✓] Processed data saved to: {csv_file}")
            
            # Also update the standard flattened file
            standard_file = os.path.join(self.nvd_dir, "flattened_nvd.csv")
            df.to_csv(standard_file, index=False)
            print(f"[✓] Updated standard file: {standard_file}")
            
            return df
        
        return None
    
    def update_databases(self):
        """Main method to update NVD databases"""
        
        print("[*] Starting NVD Database Update")
        print("=" * 50)
        
        # Create directory if needed
        os.makedirs(self.nvd_dir, exist_ok=True)
        
        # Download recent CVEs (last 30 days)
        recent_cves = self.download_recent_cves(days_back=30)
        
        if recent_cves:
            print(f"\n[*] Processing {len(recent_cves)} recent CVEs...")
            df_recent = self.save_data(recent_cves, "recent_nvd")
            
            if df_recent is not None:
                print(f"[✓] Recent CVEs summary:")
                print(f"    - Total CVEs: {len(df_recent)}")
                print(f"    - With CVSS scores: {len(df_recent[df_recent['cvss_v3_score'] != ''])}")
                print(f"    - High severity: {len(df_recent[df_recent['cvss_v3_severity'] == 'HIGH'])}")
                print(f"    - Critical severity: {len(df_recent[df_recent['cvss_v3_severity'] == 'CRITICAL'])}")
        
        # Download 2025 CVEs
        cves_2025 = self.download_2025_cves()
        
        if cves_2025:
            print(f"\n[*] Processing {len(cves_2025)} 2025 CVEs...")
            df_2025 = self.save_data(cves_2025, "2025_nvd")
            
            if df_2025 is not None:
                print(f"[✓] 2025 CVEs summary:")
                print(f"    - Total CVEs: {len(df_2025)}")
                print(f"    - With CVSS scores: {len(df_2025[df_2025['cvss_v3_score'] != ''])}")
                print(f"    - High severity: {len(df_2025[df_2025['cvss_v3_severity'] == 'HIGH'])}")
                print(f"    - Critical severity: {len(df_2025[df_2025['cvss_v3_severity'] == 'CRITICAL'])}")
                
                # Top vendors
                all_vendors = []
                for vendors_str in df_2025['vendors']:
                    if vendors_str:
                        all_vendors.extend(vendors_str.split(';'))
                        
                if all_vendors:
                    vendor_counts = pd.Series(all_vendors).value_counts().head(10)
                    print(f"\n[*] Top affected vendors in 2025:")
                    for vendor, count in vendor_counts.items():
                        print(f"    - {vendor}: {count} CVEs")
        
        print("\n[✓] NVD database update completed!")


if __name__ == "__main__":
    updater = NVDUpdater()
    updater.update_databases()